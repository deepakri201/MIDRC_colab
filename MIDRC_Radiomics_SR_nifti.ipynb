{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project  bwh-midrc-rapid-res-1655321320"
      ],
      "metadata": {
        "id": "QZr5-mEOOxyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5875a1-9b4a-4b3c-f79d-086fa3fe74d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Kk0d3lMmDp3"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bbM0Cf_94rqz"
      },
      "outputs": [],
      "source": [
        "  project_name = \"bwh-midrc-rapid-res-1655321320\"\n",
        "  bucket_name = \"midrc-analysis-bwh\"\n",
        "  bucket_path = \"bpr-results/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KZYEUFWcW6pG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "46bb684e-fea7-49da-829e-92fa1b05804b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pynrrd\n",
            "  Downloading pynrrd-1.0.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pynrrd) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pynrrd) (1.21.6)\n",
            "Collecting nptyping\n",
            "  Downloading nptyping-2.3.1-py3-none-any.whl (32 kB)\n",
            "Collecting numpy>=1.11.1\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 11.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, nptyping, pynrrd\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "Successfully installed nptyping-2.3.1 numpy-1.21.5 pynrrd-1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#install nrrd\n",
        "!pip install pynrrd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j79_pPeVRjkB",
        "outputId": "465d85ed-fcc1-4af7-b674-6bdccc3862b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.8 MB 89 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Plastimatch\n",
        "import os\n",
        "\n",
        "!sudo apt install plastimatch \n",
        "!echo $(plastimatch --version)\n",
        "\n",
        "if os.path.isdir('/content/pyplastimatch'):\n",
        "  try:\n",
        "    shutil.rmtree('/content/pyplastimatch')\n",
        "  except OSError as err:\n",
        "    print(\"Error: %s : %s\" % (\"pyplastimatch\", err.strerror)) \n",
        "# !git clone https://github.com/denbonte/pyplastimatch/ pyplastimatch\n",
        "!git clone https://github.com/AIM-Harvard/pyplastimatch.git \n",
        "\n",
        "# from pyplastimatch import pyplastimatch as pypla\n",
        "from pyplastimatch.pyplastimatch import pyplastimatch as pypla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-1TXwbUGiKL",
        "outputId": "09cf978c-66b1-4e52-c934-357a7ca4b6ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libdcmtk12 libdlib-data libdlib18 libfftw3-single3 libinsighttoolkit4.12\n",
            "  libnifti2\n",
            "Suggested packages:\n",
            "  libfftw3-bin libfftw3-dev\n",
            "The following NEW packages will be installed:\n",
            "  libdcmtk12 libdlib-data libdlib18 libfftw3-single3 libinsighttoolkit4.12\n",
            "  libnifti2 plastimatch\n",
            "0 upgraded, 7 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 76.0 MB of archives.\n",
            "After this operation, 162 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdcmtk12 amd64 3.6.2-3build3 [4,499 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdlib-data all 18.18-2build1 [63.4 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libdlib18 amd64 18.18-2build1 [251 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-single3 amd64 3.3.7-1 [764 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libnifti2 amd64 2.0.0-2build1 [102 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libinsighttoolkit4.12 amd64 4.12.2-dfsg1-1ubuntu1 [4,301 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 plastimatch amd64 1.7.0+dfsg.1-1 [2,700 kB]\n",
            "Fetched 76.0 MB in 5s (14.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 7.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libdcmtk12.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libdcmtk12_3.6.2-3build3_amd64.deb ...\n",
            "Unpacking libdcmtk12 (3.6.2-3build3) ...\n",
            "Selecting previously unselected package libdlib-data.\n",
            "Preparing to unpack .../1-libdlib-data_18.18-2build1_all.deb ...\n",
            "Unpacking libdlib-data (18.18-2build1) ...\n",
            "Selecting previously unselected package libdlib18.\n",
            "Preparing to unpack .../2-libdlib18_18.18-2build1_amd64.deb ...\n",
            "Unpacking libdlib18 (18.18-2build1) ...\n",
            "Selecting previously unselected package libfftw3-single3:amd64.\n",
            "Preparing to unpack .../3-libfftw3-single3_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-single3:amd64 (3.3.7-1) ...\n",
            "Selecting previously unselected package libnifti2.\n",
            "Preparing to unpack .../4-libnifti2_2.0.0-2build1_amd64.deb ...\n",
            "Unpacking libnifti2 (2.0.0-2build1) ...\n",
            "Selecting previously unselected package libinsighttoolkit4.12.\n",
            "Preparing to unpack .../5-libinsighttoolkit4.12_4.12.2-dfsg1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libinsighttoolkit4.12 (4.12.2-dfsg1-1ubuntu1) ...\n",
            "Selecting previously unselected package plastimatch.\n",
            "Preparing to unpack .../6-plastimatch_1.7.0+dfsg.1-1_amd64.deb ...\n",
            "Unpacking plastimatch (1.7.0+dfsg.1-1) ...\n",
            "Setting up libdlib-data (18.18-2build1) ...\n",
            "Setting up libnifti2 (2.0.0-2build1) ...\n",
            "Setting up libdlib18 (18.18-2build1) ...\n",
            "Setting up libdcmtk12 (3.6.2-3build3) ...\n",
            "Setting up libfftw3-single3:amd64 (3.3.7-1) ...\n",
            "Setting up libinsighttoolkit4.12 (4.12.2-dfsg1-1ubuntu1) ...\n",
            "Setting up plastimatch (1.7.0+dfsg.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "plastimatch version 1.7.0\n",
            "Cloning into 'pyplastimatch'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 361 (delta 38), reused 97 (delta 32), pack-reused 257\u001b[K\n",
            "Receiving objects: 100% (361/361), 55.58 MiB | 22.02 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyradiomics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7xHab-k895-",
        "outputId": "6645cd82-76f8-4a10-a47e-94bf19248e47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyradiomics\n",
            "  Downloading pyradiomics-3.0.1-cp37-cp37m-manylinux1_x86_64.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.21.5)\n",
            "Requirement already satisfied: SimpleITK>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (2.2.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.3.0)\n",
            "Collecting pykwalify>=1.6.0\n",
            "  Downloading pykwalify-1.8.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pyradiomics) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pykwalify>=1.6.0->pyradiomics) (2.8.2)\n",
            "Collecting ruamel.yaml>=0.16.0\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 42.5 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 42.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=e4d7de41e1f38deb36288d10c03b9b2a2d943d5c9bc315f6d56bc34f9f95cccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "Successfully built docopt\n",
            "Installing collected packages: ruamel.yaml.clib, ruamel.yaml, docopt, pykwalify, pyradiomics\n",
            "Successfully installed docopt-0.6.2 pykwalify-1.8.0 pyradiomics-3.0.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dcmqi \n",
        "!wget https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n",
        "!tar zxvf dcmqi-1.2.5-linux.tar.gz\n",
        "!cp dcmqi-1.2.5-linux/bin/* /usr/local/bin/"
      ],
      "metadata": {
        "id": "nb3QkfCWbbWG",
        "outputId": "eb182e8b-f11a-4807-e138-682797000286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-14 20:06:06--  https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50675718/79d3ad95-9f0c-42a4-a1c5-bf5a63461894?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221114T200606Z&X-Amz-Expires=300&X-Amz-Signature=64d7e32ada0adcc74bcedc9d870db1a5603570bcf86db6f3c8ccee20107e6e79&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50675718&response-content-disposition=attachment%3B%20filename%3Ddcmqi-1.2.5-linux.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-14 20:06:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50675718/79d3ad95-9f0c-42a4-a1c5-bf5a63461894?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221114T200606Z&X-Amz-Expires=300&X-Amz-Signature=64d7e32ada0adcc74bcedc9d870db1a5603570bcf86db6f3c8ccee20107e6e79&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50675718&response-content-disposition=attachment%3B%20filename%3Ddcmqi-1.2.5-linux.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21102129 (20M) [application/octet-stream]\n",
            "Saving to: ‘dcmqi-1.2.5-linux.tar.gz’\n",
            "\n",
            "dcmqi-1.2.5-linux.t 100%[===================>]  20.12M  12.8MB/s    in 1.6s    \n",
            "\n",
            "2022-11-14 20:06:08 (12.8 MB/s) - ‘dcmqi-1.2.5-linux.tar.gz’ saved [21102129/21102129]\n",
            "\n",
            "dcmqi-1.2.5-linux/bin/\n",
            "dcmqi-1.2.5-linux/bin/itkimage2segimage\n",
            "dcmqi-1.2.5-linux/bin/tid1500reader\n",
            "dcmqi-1.2.5-linux/bin/tid1500reader.xml\n",
            "dcmqi-1.2.5-linux/bin/itkimage2segimage.xml\n",
            "dcmqi-1.2.5-linux/bin/itkimage2paramap.xml\n",
            "dcmqi-1.2.5-linux/bin/itkimage2paramap\n",
            "dcmqi-1.2.5-linux/bin/segimage2itkimage.xml\n",
            "dcmqi-1.2.5-linux/bin/segimage2itkimage\n",
            "dcmqi-1.2.5-linux/bin/tid1500writer.xml\n",
            "dcmqi-1.2.5-linux/bin/tid1500writer\n",
            "dcmqi-1.2.5-linux/bin/paramap2itkimage\n",
            "dcmqi-1.2.5-linux/bin/paramap2itkimage.xml\n",
            "dcmqi-1.2.5-linux/share/\n",
            "dcmqi-1.2.5-linux/share/doc/\n",
            "dcmqi-1.2.5-linux/share/doc/ITK-4.10/\n",
            "dcmqi-1.2.5-linux/share/doc/ITK-4.10/itksys/\n",
            "dcmqi-1.2.5-linux/share/doc/ITK-4.10/itksys/Copyright.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QImQTiwVnvxr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install dicomweb-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HKGUrG1iAo5f"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import six\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import shutil\n",
        "from google.cloud import storage\n",
        "import nrrd\n",
        "import SimpleITK as sitk\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import transforms\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "import radiomics\n",
        "from radiomics import featureextractor  # This module is used for interaction with pyradiomics\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import nibabel as nib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sR8c3D6j1Vvh"
      },
      "outputs": [],
      "source": [
        "#%%bigquery --project=bwh-midrc-rapid-res-1655321320 ct_limited_open_a1_r1\n",
        "\n",
        "# python API is the most flexible way to query IDC BigQuery metadata tables\n",
        "from google.cloud import bigquery\n",
        "bq_client = bigquery.Client(project_name)\n",
        "\n",
        "selection_query = \"\"\"\n",
        "\n",
        "WITH\n",
        "  nlst_instances_per_series AS (\n",
        "    SELECT\n",
        "      DISTINCT(StudyInstanceUID),\n",
        "      SeriesInstanceUID,\n",
        "      COUNT(DISTINCT(SOPInstanceUID)) AS num_instances,\n",
        "      COUNT(DISTINCT(ARRAY_TO_STRING(ImagePositionPatient,\"/\"))) AS position_count,\n",
        "      COUNT(DISTINCT(ARRAY_TO_STRING(ImageOrientationPatient,\"/\"))) AS orientation_count,\n",
        "      MIN(SAFE_CAST(SliceThickness AS float64)) AS min_SliceThickness,\n",
        "      MAX(SAFE_CAST(SliceThickness AS float64)) AS max_SliceThickness,\n",
        "      MIN(SAFE_CAST(ImagePositionPatient[SAFE_OFFSET(2)] AS float64)) as min_SliceLocation, \n",
        "      MAX(SAFE_CAST(ImagePositionPatient[SAFE_OFFSET(2)] AS float64)) as max_SliceLocation,\n",
        "      STRING_AGG(DISTINCT(SAFE_CAST(\"LOCALIZER\" IN UNNEST(ImageType) AS string)),\"\") AS has_localizer\n",
        "    FROM\n",
        "      bwh-midrc-rapid-res-1655321320.midrc_dicom_us.dicom_all\n",
        "    WHERE\n",
        "      (collection_id = \"Open-R1\" or collection_id = \"Open-A1\") and Modality = \"CT\"\n",
        "    GROUP BY\n",
        "      StudyInstanceUID,\n",
        "      SeriesInstanceUID\n",
        "      ), \n",
        "  nlst_values_per_series AS (\n",
        "    SELECT \n",
        "    ANY_VALUE(dicom_all.PatientID) AS PatientID,\n",
        "    dicom_all.SeriesInstanceUID,\n",
        "    ANY_VALUE(nlst_instances_per_series.num_instances) AS num_instances,\n",
        "    ANY_VALUE(nlst_instances_per_series.max_SliceThickness) AS SliceThickness,\n",
        "    ANY_VALUE((nlst_instances_per_series.max_SliceLocation - nlst_instances_per_series.min_SliceLocation)) AS PatientHeightScanned\n",
        "  FROM\n",
        "    bwh-midrc-rapid-res-1655321320.midrc_dicom_us.dicom_all AS dicom_all\n",
        "  JOIN\n",
        "    nlst_instances_per_series\n",
        "  ON\n",
        "    dicom_all.SeriesInstanceUID = nlst_instances_per_series.SeriesInstanceUID\n",
        "  WHERE\n",
        "    min_SliceThickness >= 1.5 \n",
        "    AND max_SliceThickness <= 3.5 \n",
        "    AND nlst_instances_per_series.num_instances > 100\n",
        "    AND nlst_instances_per_series.num_instances/nlst_instances_per_series.position_count = 1\n",
        "    AND nlst_instances_per_series.orientation_count = 1\n",
        "    AND has_localizer = \"false\"\n",
        "  GROUP BY\n",
        "    SeriesInstanceUID\n",
        "  )\n",
        "  SELECT \n",
        "    dicom_all.PatientID,\n",
        "    dicom_all.StudyInstanceUID,\n",
        "    dicom_all.SeriesInstanceUID,\n",
        "    dicom_all.SOPInstanceUID,\n",
        "    dicom_all.collection_id,\n",
        "    dicom_all.PatientAge,\n",
        "    dicom_all.PatientWeight,\n",
        "    nlst_values_per_series.num_instances,\n",
        "    nlst_values_per_series.SliceThickness,\n",
        "    nlst_values_per_series.PatientHeightScanned\n",
        "  FROM\n",
        "    bwh-midrc-rapid-res-1655321320.midrc_dicom_us.dicom_all AS dicom_all\n",
        "  JOIN\n",
        "    nlst_values_per_series \n",
        "  ON\n",
        "    dicom_all.SeriesInstanceUID = nlst_values_per_series.SeriesInstanceUID\n",
        "  \"\"\"\n",
        "\n",
        "selection_result = bq_client.query(selection_query)\n",
        "ct_limited_open_a1_r1 = selection_result.result().to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ct_limited_open_a1_r1"
      ],
      "metadata": {
        "id": "JIfLBM8axo2v",
        "outputId": "c2b97dea-3fc9-4465-d8aa-0bde5c5899a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               PatientID                                   StudyInstanceUID  \\\n",
              "0       10000364-1906862  2.16.840.1.114274.1818.47315073017873895969904...   \n",
              "1       10000364-1256217  2.16.840.1.114274.1818.47907986328652897162903...   \n",
              "2       10000364-1461701  2.16.840.1.114274.1818.52001131290310374926881...   \n",
              "3       10000364-5543671  2.16.840.1.114274.1818.49036101659914773221332...   \n",
              "4       10000364-1746899  2.16.840.1.114274.1818.55649572519608023736821...   \n",
              "...                  ...                                                ...   \n",
              "205258  10000364-1380451  2.16.840.1.114274.1818.57618452499506629833358...   \n",
              "205259  10000364-1380451  2.16.840.1.114274.1818.57618452499506629833358...   \n",
              "205260  10000364-1380451  2.16.840.1.114274.1818.57618452499506629833358...   \n",
              "205261  10000364-1380451  2.16.840.1.114274.1818.57618452499506629833358...   \n",
              "205262  10000364-1380451  2.16.840.1.114274.1818.57618452499506629833358...   \n",
              "\n",
              "                                        SeriesInstanceUID  \\\n",
              "0       2.16.840.1.114274.1818.52179396729050912776452...   \n",
              "1       2.16.840.1.114274.1818.54437891559047211071016...   \n",
              "2       2.16.840.1.114274.1818.52627084067014710255515...   \n",
              "3       2.16.840.1.114274.1818.51599489074206889371699...   \n",
              "4       2.16.840.1.114274.1818.47692890739865335987492...   \n",
              "...                                                   ...   \n",
              "205258  2.16.840.1.114274.1818.47339477280213282808626...   \n",
              "205259  2.16.840.1.114274.1818.47339477280213282808626...   \n",
              "205260  2.16.840.1.114274.1818.55681874733043414677313...   \n",
              "205261  2.16.840.1.114274.1818.56065848524921294672761...   \n",
              "205262  2.16.840.1.114274.1818.47339477280213282808626...   \n",
              "\n",
              "                                           SOPInstanceUID collection_id  \\\n",
              "0       2.16.840.1.114274.1818.55724131262165094961917...       Open-A1   \n",
              "1       2.16.840.1.114274.1818.54715776599439465647821...       Open-A1   \n",
              "2       2.16.840.1.114274.1818.46310395716565719611583...       Open-A1   \n",
              "3       2.16.840.1.114274.1818.53104187086697648967435...       Open-A1   \n",
              "4       2.16.840.1.114274.1818.56312071072935286328293...       Open-A1   \n",
              "...                                                   ...           ...   \n",
              "205258  2.16.840.1.114274.1818.57308640621182620571741...       Open-A1   \n",
              "205259  2.16.840.1.114274.1818.53615806610676762091027...       Open-A1   \n",
              "205260  2.16.840.1.114274.1818.49896072318637343613721...       Open-A1   \n",
              "205261  2.16.840.1.114274.1818.48070555096422806983956...       Open-A1   \n",
              "205262  2.16.840.1.114274.1818.57097897487033534801057...       Open-A1   \n",
              "\n",
              "       PatientAge PatientWeight  num_instances  SliceThickness  \\\n",
              "0            024Y       107.502            207             1.5   \n",
              "1            034Y       158.759            159             1.5   \n",
              "2            018Y        60.782            179             1.5   \n",
              "3            041Y        61.145            167             2.0   \n",
              "4            027Y       104.781            118             1.5   \n",
              "...           ...           ...            ...             ...   \n",
              "205258       087Y         80.06            130             1.5   \n",
              "205259       087Y         80.06            130             1.5   \n",
              "205260       087Y         80.06            268             1.5   \n",
              "205261       087Y         80.06            128             1.5   \n",
              "205262       087Y         80.06            130             1.5   \n",
              "\n",
              "        PatientHeightScanned  \n",
              "0                       0.00  \n",
              "1                       0.00  \n",
              "2                     267.00  \n",
              "3                     332.00  \n",
              "4                       0.00  \n",
              "...                      ...  \n",
              "205258                244.50  \n",
              "205259                244.50  \n",
              "205260                 20.89  \n",
              "205261                243.00  \n",
              "205262                244.50  \n",
              "\n",
              "[205263 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b9f2c08-7333-434a-a512-5237caf42e00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PatientID</th>\n",
              "      <th>StudyInstanceUID</th>\n",
              "      <th>SeriesInstanceUID</th>\n",
              "      <th>SOPInstanceUID</th>\n",
              "      <th>collection_id</th>\n",
              "      <th>PatientAge</th>\n",
              "      <th>PatientWeight</th>\n",
              "      <th>num_instances</th>\n",
              "      <th>SliceThickness</th>\n",
              "      <th>PatientHeightScanned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000364-1906862</td>\n",
              "      <td>2.16.840.1.114274.1818.47315073017873895969904...</td>\n",
              "      <td>2.16.840.1.114274.1818.52179396729050912776452...</td>\n",
              "      <td>2.16.840.1.114274.1818.55724131262165094961917...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>024Y</td>\n",
              "      <td>107.502</td>\n",
              "      <td>207</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000364-1256217</td>\n",
              "      <td>2.16.840.1.114274.1818.47907986328652897162903...</td>\n",
              "      <td>2.16.840.1.114274.1818.54437891559047211071016...</td>\n",
              "      <td>2.16.840.1.114274.1818.54715776599439465647821...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>034Y</td>\n",
              "      <td>158.759</td>\n",
              "      <td>159</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000364-1461701</td>\n",
              "      <td>2.16.840.1.114274.1818.52001131290310374926881...</td>\n",
              "      <td>2.16.840.1.114274.1818.52627084067014710255515...</td>\n",
              "      <td>2.16.840.1.114274.1818.46310395716565719611583...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>018Y</td>\n",
              "      <td>60.782</td>\n",
              "      <td>179</td>\n",
              "      <td>1.5</td>\n",
              "      <td>267.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10000364-5543671</td>\n",
              "      <td>2.16.840.1.114274.1818.49036101659914773221332...</td>\n",
              "      <td>2.16.840.1.114274.1818.51599489074206889371699...</td>\n",
              "      <td>2.16.840.1.114274.1818.53104187086697648967435...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>041Y</td>\n",
              "      <td>61.145</td>\n",
              "      <td>167</td>\n",
              "      <td>2.0</td>\n",
              "      <td>332.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10000364-1746899</td>\n",
              "      <td>2.16.840.1.114274.1818.55649572519608023736821...</td>\n",
              "      <td>2.16.840.1.114274.1818.47692890739865335987492...</td>\n",
              "      <td>2.16.840.1.114274.1818.56312071072935286328293...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>027Y</td>\n",
              "      <td>104.781</td>\n",
              "      <td>118</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205258</th>\n",
              "      <td>10000364-1380451</td>\n",
              "      <td>2.16.840.1.114274.1818.57618452499506629833358...</td>\n",
              "      <td>2.16.840.1.114274.1818.47339477280213282808626...</td>\n",
              "      <td>2.16.840.1.114274.1818.57308640621182620571741...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>087Y</td>\n",
              "      <td>80.06</td>\n",
              "      <td>130</td>\n",
              "      <td>1.5</td>\n",
              "      <td>244.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205259</th>\n",
              "      <td>10000364-1380451</td>\n",
              "      <td>2.16.840.1.114274.1818.57618452499506629833358...</td>\n",
              "      <td>2.16.840.1.114274.1818.47339477280213282808626...</td>\n",
              "      <td>2.16.840.1.114274.1818.53615806610676762091027...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>087Y</td>\n",
              "      <td>80.06</td>\n",
              "      <td>130</td>\n",
              "      <td>1.5</td>\n",
              "      <td>244.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205260</th>\n",
              "      <td>10000364-1380451</td>\n",
              "      <td>2.16.840.1.114274.1818.57618452499506629833358...</td>\n",
              "      <td>2.16.840.1.114274.1818.55681874733043414677313...</td>\n",
              "      <td>2.16.840.1.114274.1818.49896072318637343613721...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>087Y</td>\n",
              "      <td>80.06</td>\n",
              "      <td>268</td>\n",
              "      <td>1.5</td>\n",
              "      <td>20.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205261</th>\n",
              "      <td>10000364-1380451</td>\n",
              "      <td>2.16.840.1.114274.1818.57618452499506629833358...</td>\n",
              "      <td>2.16.840.1.114274.1818.56065848524921294672761...</td>\n",
              "      <td>2.16.840.1.114274.1818.48070555096422806983956...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>087Y</td>\n",
              "      <td>80.06</td>\n",
              "      <td>128</td>\n",
              "      <td>1.5</td>\n",
              "      <td>243.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205262</th>\n",
              "      <td>10000364-1380451</td>\n",
              "      <td>2.16.840.1.114274.1818.57618452499506629833358...</td>\n",
              "      <td>2.16.840.1.114274.1818.47339477280213282808626...</td>\n",
              "      <td>2.16.840.1.114274.1818.57097897487033534801057...</td>\n",
              "      <td>Open-A1</td>\n",
              "      <td>087Y</td>\n",
              "      <td>80.06</td>\n",
              "      <td>130</td>\n",
              "      <td>1.5</td>\n",
              "      <td>244.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205263 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b9f2c08-7333-434a-a512-5237caf42e00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b9f2c08-7333-434a-a512-5237caf42e00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b9f2c08-7333-434a-a512-5237caf42e00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_series(study_instance_uid, series_instance_uid, sop_instance_uids, dest_dir):\n",
        "  import pydicom\n",
        "  token = !gcloud auth print-access-token\n",
        "  token = token[0]\n",
        "\n",
        "  PROJECT_ID=\"bwh-midrc-rapid-res-1655321320\"\n",
        "  REGION=\"us-central1\"\n",
        "\n",
        "  DATASET_ID=\"midrc\"\n",
        "  DICOM_STORE_ID=\"midrc-dicom\"\n",
        "  \n",
        "  my_project = \"bwh-midrc-rapid-res-1655321320\"\n",
        "  location = \"us-central1\"\n",
        "  dataset_id = \"midrc\"\n",
        "  dicom_store_id = \"midrc-dicom\"\n",
        "\n",
        "  url = f\"https://healthcare.googleapis.com/v1/projects/{my_project}/locations/{location}/datasets/{dataset_id}/dicomStores/{dicom_store_id}/dicomWeb\"\n",
        "  headers = {\n",
        "      \"Authorization\" : \"Bearer %s\" % token\n",
        "  }\n",
        "\n",
        "  import dicomweb_client\n",
        "\n",
        "  client = dicomweb_client.api.DICOMwebClient(url, headers=headers)\n",
        "\n",
        "  idx=0\n",
        "  for sop_instance_uid in sop_instance_uids:\n",
        "    retrievedInstance = client.retrieve_instance(\n",
        "                study_instance_uid=study_instance_uid,\n",
        "                series_instance_uid=series_instance_uid,\n",
        "                sop_instance_uid=sop_instance_uid)\n",
        "    pydicom.filewriter.write_file(f\"{dest_dir}/file{idx}.dcm\", retrievedInstance)\n",
        "    idx+=1"
      ],
      "metadata": {
        "id": "KE05zkHQnxrn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0q6ovBXnRWeY"
      },
      "outputs": [],
      "source": [
        "def file_exists_in_bucket(project_name, bucket_name, file_gs_uri):\n",
        "  \n",
        "  \"\"\"\n",
        "  Check whether a file exists in the specified Google Cloud Storage Bucket.\n",
        "\n",
        "  Arguments:\n",
        "    project_name : required - name of the GCP project.\n",
        "    bucket_name  : required - name of the bucket (without gs://)\n",
        "    file_gs_uri  : required - file GS URI\n",
        "  \n",
        "  Returns:\n",
        "    file_exists : boolean variable, True if the file exists in the specified,\n",
        "                  bucket, at the specified location; False if it doesn't.\n",
        "\n",
        "  Outputs:\n",
        "    This function [...]\n",
        "  \"\"\"\n",
        "\n",
        "  storage_client = storage.Client(project = project_name)\n",
        "  bucket = storage_client.get_bucket(bucket_name)\n",
        "  \n",
        "  bucket_gs_url = \"gs://%s/\"%(bucket_name)\n",
        "  path_to_file_relative = file_gs_uri.split(bucket_gs_url)[-1]\n",
        "\n",
        "  print(\"Searching %s for: \\n%s\\n\"%(bucket_gs_url, path_to_file_relative))\n",
        "\n",
        "  file_exists = bucket.blob(path_to_file_relative).exists(storage_client)\n",
        "  \n",
        "  return file_exists"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "urllib3_logger = logging.getLogger('urllib3')\n",
        "urllib3_logger.setLevel(logging.CRITICAL) # suppress messages upon download"
      ],
      "metadata": {
        "id": "RQjDEsQN_z71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client(project = project_name)\n",
        "#bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "series_instance_uids = []\n",
        "\n",
        "#blobs = storage_client.list_blobs(bucket)\n",
        "blobs = storage_client.list_blobs(bucket_name, prefix=bucket_path) #, delimiter='/') #don't search in non-axial sub-folder\n",
        "for blob in blobs:\n",
        "    bn = blob.name \n",
        "    # ex: bpr-results/1.2.826.0.1.3680043.10.474.419639.105799060738901793068313281334.json\n",
        "    bs = bn.split('.')\n",
        "    if bs[-1] == 'json':\n",
        "      #print(bn)\n",
        "      bss = bn.split('/')[1]\n",
        "      #print(bss)\n",
        "      bs3 = bss.split('.')\n",
        "      bs4 = '.'.join(bs3[:-1])\n",
        "      series_instance_uids.append(bs4)\n",
        "\n",
        "print(series_instance_uids[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hEvqjcFUMoF",
        "outputId": "d541cdb0-e8e7-4a41-8e33-148712680824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1.2.826.0.1.3680043.10.474.419639.105799060738901793068313281334', '1.2.826.0.1.3680043.10.474.419639.106364025147079899289440200715', '1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952', '1.2.826.0.1.3680043.10.474.419639.189346812051260775638656981947', '1.2.826.0.1.3680043.10.474.419639.192916356998524553834723357563', '1.2.826.0.1.3680043.10.474.419639.198735019931123383691750806063', '1.2.826.0.1.3680043.10.474.419639.249044315484665760654506668895', '1.2.826.0.1.3680043.10.474.419639.259584978733948574762940092562', '1.2.826.0.1.3680043.10.474.419639.269534881585852761235289087419', '1.2.826.0.1.3680043.10.474.419639.272117657178318732150423166273']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(series_instance_uids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHEqz7uhwsq0",
        "outputId": "3542b56a-f9a9-42e9-e2f4-89c05908420f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client(project = project_name)\n",
        "#bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "series_instance_uids = []\n",
        "\n",
        "#blobs = storage_client.list_blobs(bucket)\n",
        "blobs = storage_client.list_blobs(bucket_name, prefix=bucket_path, delimiter='/')\n",
        "for blob in blobs:\n",
        "    bn = blob.name \n",
        "    # ex: bpr-results/1.2.826.0.1.3680043.10.474.419639.105799060738901793068313281334.json\n",
        "    (r, ext) = os.path.splitext(bn)\n",
        "    #print(r,ext)\n",
        "    if ext == '.json':\n",
        "      u = os.path.split(r)[-1]\n",
        "      #print(u)\n",
        "      series_instance_uids.append(u)\n",
        "\n",
        "print(series_instance_uids[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOCZFuo4YG6C",
        "outputId": "79b494f4-0aef-4459-a432-298ada93356d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1.2.826.0.1.3680043.10.474.419639.105799060738901793068313281334', '1.2.826.0.1.3680043.10.474.419639.106364025147079899289440200715', '1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952', '1.2.826.0.1.3680043.10.474.419639.189346812051260775638656981947', '1.2.826.0.1.3680043.10.474.419639.192916356998524553834723357563', '1.2.826.0.1.3680043.10.474.419639.198735019931123383691750806063', '1.2.826.0.1.3680043.10.474.419639.249044315484665760654506668895', '1.2.826.0.1.3680043.10.474.419639.259584978733948574762940092562', '1.2.826.0.1.3680043.10.474.419639.269534881585852761235289087419', '1.2.826.0.1.3680043.10.474.419639.272117657178318732150423166273']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(series_instance_uids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bZ63W3pNZyX",
        "outputId": "ef80aae2-539f-42c8-a44e-feb8c4d19f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = ct_limited_open_a1_r1\n",
        "k=0\n",
        "\n",
        "good_seriesuids = []\n",
        "\n",
        "#series_instance_uids = ['1.2.826.0.1.3680043.10.474.419639.106364025147079899289440200715']\n",
        "\n",
        "for seriesuid in series_instance_uids:\n",
        "  #print(seriesuid)\n",
        "  studyuids = list(set(df[df['SeriesInstanceUID']==seriesuid]['StudyInstanceUID'].tolist()))\n",
        "  if len(studyuids)>0:\n",
        "    k=k+1\n",
        "    #print(seriesuid)\n",
        "    studyuid = studyuids[0]\n",
        "    sops = df[ (df['StudyInstanceUID']==studyuid) & (df['SeriesInstanceUID']==seriesuid) ]['SOPInstanceUID'].tolist()\n",
        "    print(len(sops))\n",
        "    #download_series(studyuid, seriesuid, sops, path_downloaded)\n",
        "    good_seriesuids.append(seriesuid)\n",
        "print(k)"
      ],
      "metadata": {
        "id": "4xxeSrvYoouz",
        "outputId": "648f4e00-9566-4982-91ea-ecf41b66d550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178\n",
            "180\n",
            "145\n",
            "193\n",
            "111\n",
            "184\n",
            "152\n",
            "262\n",
            "194\n",
            "272\n",
            "152\n",
            "206\n",
            "271\n",
            "194\n",
            "114\n",
            "658\n",
            "106\n",
            "233\n",
            "997\n",
            "466\n",
            "209\n",
            "214\n",
            "427\n",
            "915\n",
            "172\n",
            "735\n",
            "262\n",
            "194\n",
            "115\n",
            "133\n",
            "133\n",
            "165\n",
            "704\n",
            "189\n",
            "199\n",
            "199\n",
            "202\n",
            "252\n",
            "118\n",
            "153\n",
            "122\n",
            "171\n",
            "165\n",
            "704\n",
            "165\n",
            "707\n",
            "170\n",
            "143\n",
            "158\n",
            "158\n",
            "301\n",
            "243\n",
            "123\n",
            "123\n",
            "107\n",
            "187\n",
            "132\n",
            "132\n",
            "115\n",
            "229\n",
            "103\n",
            "205\n",
            "163\n",
            "144\n",
            "141\n",
            "186\n",
            "118\n",
            "232\n",
            "265\n",
            "162\n",
            "115\n",
            "119\n",
            "131\n",
            "103\n",
            "186\n",
            "165\n",
            "140\n",
            "163\n",
            "237\n",
            "160\n",
            "131\n",
            "146\n",
            "199\n",
            "199\n",
            "365\n",
            "158\n",
            "137\n",
            "185\n",
            "201\n",
            "152\n",
            "163\n",
            "194\n",
            "208\n",
            "178\n",
            "217\n",
            "116\n",
            "113\n",
            "139\n",
            "137\n",
            "280\n",
            "163\n",
            "156\n",
            "132\n",
            "233\n",
            "124\n",
            "229\n",
            "113\n",
            "199\n",
            "149\n",
            "175\n",
            "143\n",
            "107\n",
            "175\n",
            "123\n",
            "207\n",
            "164\n",
            "114\n",
            "105\n",
            "157\n",
            "157\n",
            "130\n",
            "162\n",
            "126\n",
            "116\n",
            "194\n",
            "120\n",
            "149\n",
            "599\n",
            "145\n",
            "170\n",
            "137\n",
            "232\n",
            "141\n",
            "159\n",
            "179\n",
            "143\n",
            "167\n",
            "143\n",
            "135\n",
            "111\n",
            "321\n",
            "178\n",
            "171\n",
            "218\n",
            "190\n",
            "209\n",
            "319\n",
            "122\n",
            "150\n",
            "140\n",
            "212\n",
            "164\n",
            "230\n",
            "182\n",
            "200\n",
            "104\n",
            "143\n",
            "151\n",
            "301\n",
            "101\n",
            "178\n",
            "151\n",
            "179\n",
            "156\n",
            "209\n",
            "115\n",
            "172\n",
            "200\n",
            "219\n",
            "158\n",
            "204\n",
            "184\n",
            "233\n",
            "118\n",
            "168\n",
            "239\n",
            "126\n",
            "128\n",
            "136\n",
            "204\n",
            "140\n",
            "273\n",
            "176\n",
            "127\n",
            "149\n",
            "207\n",
            "128\n",
            "158\n",
            "146\n",
            "139\n",
            "164\n",
            "163\n",
            "168\n",
            "205\n",
            "135\n",
            "135\n",
            "140\n",
            "146\n",
            "173\n",
            "113\n",
            "156\n",
            "125\n",
            "139\n",
            "119\n",
            "216\n",
            "599\n",
            "141\n",
            "125\n",
            "123\n",
            "193\n",
            "200\n",
            "146\n",
            "153\n",
            "293\n",
            "194\n",
            "217\n",
            "201\n",
            "123\n",
            "261\n",
            "114\n",
            "107\n",
            "199\n",
            "145\n",
            "185\n",
            "103\n",
            "218\n",
            "189\n",
            "205\n",
            "108\n",
            "178\n",
            "115\n",
            "171\n",
            "120\n",
            "162\n",
            "189\n",
            "403\n",
            "229\n",
            "188\n",
            "108\n",
            "118\n",
            "194\n",
            "283\n",
            "200\n",
            "115\n",
            "143\n",
            "218\n",
            "136\n",
            "153\n",
            "130\n",
            "114\n",
            "136\n",
            "157\n",
            "137\n",
            "141\n",
            "207\n",
            "209\n",
            "233\n",
            "180\n",
            "113\n",
            "179\n",
            "145\n",
            "122\n",
            "105\n",
            "200\n",
            "179\n",
            "108\n",
            "108\n",
            "145\n",
            "149\n",
            "143\n",
            "150\n",
            "140\n",
            "182\n",
            "113\n",
            "181\n",
            "118\n",
            "284\n",
            "145\n",
            "116\n",
            "194\n",
            "163\n",
            "141\n",
            "137\n",
            "217\n",
            "113\n",
            "190\n",
            "199\n",
            "172\n",
            "167\n",
            "152\n",
            "114\n",
            "191\n",
            "208\n",
            "173\n",
            "219\n",
            "368\n",
            "163\n",
            "139\n",
            "209\n",
            "150\n",
            "218\n",
            "194\n",
            "149\n",
            "143\n",
            "101\n",
            "139\n",
            "218\n",
            "150\n",
            "124\n",
            "115\n",
            "160\n",
            "185\n",
            "193\n",
            "150\n",
            "150\n",
            "180\n",
            "133\n",
            "224\n",
            "199\n",
            "208\n",
            "204\n",
            "149\n",
            "146\n",
            "108\n",
            "155\n",
            "107\n",
            "179\n",
            "150\n",
            "163\n",
            "270\n",
            "132\n",
            "217\n",
            "229\n",
            "170\n",
            "151\n",
            "151\n",
            "445\n",
            "160\n",
            "163\n",
            "132\n",
            "211\n",
            "145\n",
            "218\n",
            "148\n",
            "150\n",
            "209\n",
            "130\n",
            "148\n",
            "207\n",
            "200\n",
            "178\n",
            "217\n",
            "167\n",
            "119\n",
            "265\n",
            "180\n",
            "178\n",
            "190\n",
            "142\n",
            "297\n",
            "141\n",
            "217\n",
            "193\n",
            "103\n",
            "330\n",
            "154\n",
            "218\n",
            "202\n",
            "196\n",
            "140\n",
            "129\n",
            "197\n",
            "142\n",
            "210\n",
            "143\n",
            "118\n",
            "163\n",
            "148\n",
            "119\n",
            "166\n",
            "139\n",
            "218\n",
            "132\n",
            "130\n",
            "154\n",
            "200\n",
            "170\n",
            "170\n",
            "158\n",
            "208\n",
            "204\n",
            "109\n",
            "199\n",
            "176\n",
            "108\n",
            "136\n",
            "182\n",
            "217\n",
            "138\n",
            "212\n",
            "153\n",
            "150\n",
            "233\n",
            "122\n",
            "200\n",
            "216\n",
            "151\n",
            "200\n",
            "204\n",
            "118\n",
            "131\n",
            "112\n",
            "113\n",
            "132\n",
            "142\n",
            "146\n",
            "207\n",
            "211\n",
            "135\n",
            "143\n",
            "107\n",
            "114\n",
            "125\n",
            "107\n",
            "148\n",
            "137\n",
            "182\n",
            "140\n",
            "739\n",
            "154\n",
            "289\n",
            "150\n",
            "137\n",
            "185\n",
            "217\n",
            "137\n",
            "218\n",
            "200\n",
            "126\n",
            "146\n",
            "128\n",
            "199\n",
            "204\n",
            "297\n",
            "200\n",
            "209\n",
            "154\n",
            "115\n",
            "161\n",
            "146\n",
            "134\n",
            "120\n",
            "161\n",
            "337\n",
            "201\n",
            "122\n",
            "149\n",
            "163\n",
            "142\n",
            "145\n",
            "157\n",
            "243\n",
            "139\n",
            "145\n",
            "107\n",
            "135\n",
            "140\n",
            "141\n",
            "136\n",
            "133\n",
            "172\n",
            "208\n",
            "140\n",
            "157\n",
            "149\n",
            "145\n",
            "194\n",
            "171\n",
            "136\n",
            "116\n",
            "123\n",
            "843\n",
            "208\n",
            "176\n",
            "142\n",
            "154\n",
            "226\n",
            "149\n",
            "126\n",
            "161\n",
            "165\n",
            "165\n",
            "209\n",
            "107\n",
            "494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a list of seriesuid's in the bucket\n",
        "storage_client = storage.Client()\n",
        "blobs = storage_client.list_blobs(bucket_name)\n",
        "s = []\n",
        "k=0\n",
        "for b in blobs:\n",
        "  #print('raw', b.name)\n",
        "  p = os.path.split(b.name)\n",
        "  #print(p)\n",
        "  # skip non-axial and folders\n",
        "  # temporarily autoremove any slashes from bucket_path\n",
        "  if p[0]==bucket_path.replace('/','') and p[1].split('.')[-1]=='nrrd':\n",
        "    k +=1\n",
        "    seriesuid_tmp = '.'.join(p[1].split('.')[:-1])\n",
        "    s.append(seriesuid_tmp)\n",
        "    if k%10==0:\n",
        "      print(k,' ', end='')\n",
        "    if k%120==0:\n",
        "        print('')\n",
        "seriesuid_list = list(set([x.split('_')[1] for x in s ]))\n",
        "print('\\n',len(seriesuid_list))"
      ],
      "metadata": {
        "id": "Ku6ZTZsevVDR",
        "outputId": "62c64dfa-a5ae-498d-cd61-3af821b371d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10  20  30  40  50  60  70  80  90  100  110  120  \n",
            "130  140  150  160  170  180  190  200  210  220  230  240  \n",
            "250  260  270  280  290  300  310  320  330  340  350  360  \n",
            "370  380  390  400  410  420  430  440  450  460  470  480  \n",
            "490  500  510  520  530  540  550  560  570  580  590  600  \n",
            "610  620  630  640  650  660  670  680  690  700  710  720  \n",
            "730  740  750  760  770  780  790  800  810  820  830  840  \n",
            "850  860  870  880  890  900  910  920  930  940  950  960  \n",
            "970  980  \n",
            " 494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload files:\n",
        "# - parameter file for radiomics \n",
        "# - meta json for segmentation\n",
        "# - segment code mapping\n",
        "# - shape feature code mapping\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "ZjUBvc61FIuB",
        "outputId": "68843fb4-8d2b-442c-ab45-5068c1c6a6b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d95a950-a8f3-4302-b8b9-ac32b52c7a8c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d95a950-a8f3-4302-b8b9-ac32b52c7a8c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lung_seg_meta.json to lung_seg_meta.json\n",
            "Saving param_ct.yaml to param_ct.yaml\n",
            "Saving segments_code_mapping.csv to segments_code_mapping.csv\n",
            "Saving shape_features_code_mapping.csv to shape_features_code_mapping.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the extractor\n",
        "  extractor = featureextractor.RadiomicsFeatureExtractor(fn_param)\n",
        "\n",
        "  # lung masks\n",
        "  lungs = fn_seg_nrrd\n",
        "  lungs, lungsheader = nrrd.read(lungs)\n",
        "\n",
        "  right_lung = np.zeros(lungs.shape)\n",
        "  temp =np.where(lungs==1) \n",
        "  right_lung[temp]=1\n",
        "\n",
        "  left_lung = np.zeros(lungs.shape)\n",
        "  temp =np.where(lungs==2) \n",
        "  left_lung[temp]=1\n",
        "\n",
        "  fn_right_lung = os.path.join(path_nrrd, 'rlung_%s.nrrd' % seriesuid)\n",
        "  fn_left_lung =  os.path.join(path_nrrd, 'llung_%s.nrrd' % seriesuid)\n",
        "\n",
        "  nrrd.write(fn_right_lung, right_lung, header = lungsheader)\n",
        "  nrrd.write(fn_left_lung, left_lung, header = lungsheader)\n",
        "\n",
        "  # process the lungs\n",
        "  result = extractor.execute(fn_ct_nrrd, fn_right_lung)\n",
        "  for key, val in six.iteritems(result):\n",
        "    print(\"\\t%s: %s\" %(key, val))\n",
        "  fn_out = '/content/radiomics_features_right_lung_%s.csv' % seriesuid\n",
        "  df = pd.DataFrame.from_dict(six.iteritems(result))# columns = ['Feature','Value'])\n",
        "  df.to_csv(fn_out, index=False)\n",
        "\n",
        "  result = extractor.execute(fn_ct_nrrd, fn_left_lung)\n",
        "  for key, val in six.iteritems(result):\n",
        "    print(\"\\t%s: %s\" %(key, val))\n",
        "  fn_out = '/content/radiomics_features_left_lung_%s.csv' % seriesuid\n",
        "  df = pd.DataFrame.from_dict(six.iteritems(result))# columns = ['Feature','Value'])\n",
        "  df.to_csv(fn_out, index=False)\n"
      ],
      "metadata": {
        "id": "xo_uITXHFlX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall highdicom\n",
        "!git clone https://github.com/herrmannlab/highdicom.git\n",
        "#!cd highdicom && python setup.py install\n",
        "!cd highdicom && pip install .\n",
        "\n",
        "!pip install pydicom\n"
      ],
      "metadata": {
        "id": "juNDFA2y988w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70464641-abeb-49bf-aaef-11f7899ada5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping highdicom as it is not installed.\u001b[0m\n",
            "Cloning into 'highdicom'...\n",
            "remote: Enumerating objects: 5652, done.\u001b[K\n",
            "remote: Counting objects: 100% (2205/2205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (563/563), done.\u001b[K\n",
            "remote: Total 5652 (delta 1871), reused 1757 (delta 1565), pack-reused 3447\u001b[K\n",
            "Receiving objects: 100% (5652/5652), 3.13 MiB | 12.04 MiB/s, done.\n",
            "Resolving deltas: 100% (3674/3674), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/highdicom\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: pydicom>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from highdicom==0.20.0) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from highdicom==0.20.0) (1.21.5)\n",
            "Requirement already satisfied: pillow>=8.3 in /usr/local/lib/python3.7/dist-packages (from highdicom==0.20.0) (9.3.0)\n",
            "Collecting pillow-jpls>=1.0\n",
            "  Downloading pillow_jpls-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (339 kB)\n",
            "\u001b[K     |████████████████████████████████| 339 kB 6.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: highdicom\n",
            "  Building wheel for highdicom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for highdicom: filename=highdicom-0.20.0-py3-none-any.whl size=800101 sha256=851d6b5d0e6925a83d6b16e6015a086aa99965ae7b3eb92379cbc8a4886e75e7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fd7wh2wb/wheels/2c/3f/a0/cadbe6603e979b07733495973de6e1f45b81d2295bf6a358a3\n",
            "Successfully built highdicom\n",
            "Installing collected packages: pillow-jpls, highdicom\n",
            "Successfully installed highdicom-0.20.0 pillow-jpls-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.7/dist-packages (2.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages for the structured report \n",
        "\n",
        "import highdicom\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import highdicom as hd\n",
        "\n",
        "from pydicom.uid import generate_uid\n",
        "from pydicom.filereader import dcmread\n",
        "from pydicom.sr.codedict import codes\n",
        "\n",
        "from highdicom.sr.content import (\n",
        "    FindingSite,\n",
        "    ImageRegion,\n",
        "    ImageRegion3D,\n",
        "    SourceImageForRegion,\n",
        "    SourceImageForMeasurement,\n",
        "    SourceImageForMeasurementGroup\n",
        ")\n",
        "from highdicom.sr.enum import GraphicTypeValues3D\n",
        "from highdicom.sr.enum import GraphicTypeValues\n",
        "from highdicom.sr.sop import Comprehensive3DSR, ComprehensiveSR\n",
        "from highdicom.sr.templates import (\n",
        "    DeviceObserverIdentifyingAttributes,\n",
        "    Measurement,\n",
        "    MeasurementProperties,\n",
        "    MeasurementReport,\n",
        "    MeasurementsAndQualitativeEvaluations,\n",
        "    ObservationContext,\n",
        "    ObserverContext,\n",
        "    PersonObserverIdentifyingAttributes,\n",
        "    PlanarROIMeasurementsAndQualitativeEvaluations,\n",
        "    RelationshipTypeValues,\n",
        "    TrackingIdentifier,\n",
        "    QualitativeEvaluation,\n",
        "    ImageLibrary,\n",
        "    ImageLibraryEntryDescriptors\n",
        ")\n",
        "from highdicom.sr.value_types import (\n",
        "    CodedConcept,\n",
        "    CodeContentItem,\n",
        ")\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger(\"highdicom.sr.sop\")\n",
        "logger.setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "F5TvCItyDlxs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_and_names_from_metadata_json(dicomseg_json):\n",
        "\n",
        "  \"\"\"Returns two lists containing the label values and the corresponding\n",
        "     CodeMeaning values\n",
        "\n",
        "  Inputs: \n",
        "    dicomseg_json : metajson file\n",
        "\n",
        "  Outputs:\n",
        "    label_values  : label values from the metajson file \n",
        "    label_names   : the corresponding CodeMeaning values \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  f = open(dicomseg_json)\n",
        "  meta_json = json.load(f)\n",
        "\n",
        "  print(meta_json)\n",
        "\n",
        "  num_regions = len(meta_json['segmentAttributes'][0])\n",
        "  print ('num_regions: ' + str(num_regions))\n",
        "\n",
        "  label_values = []\n",
        "  label_names = [] \n",
        "  for n in range(0,num_regions):\n",
        "    # label_values.append(n)\n",
        "    label_value = meta_json['segmentAttributes'][0][n]['labelID']\n",
        "    #label_name = meta_json['segmentAttributes'][0][n]['SegmentedPropertyTypeCodeSequence']['CodeMeaning']\n",
        "    # NS - \n",
        "    #label_name = meta_json['segmentAttributes'][0][n]['SegmentedPropertyTypeCodeSequence']['CodeMeaning'] +'_'+str(label_value)\n",
        "    label_name = meta_json['segmentAttributes'][0][n]['SegmentDescription'] # Left lung, Right lung\n",
        "    label_values.append(label_value)\n",
        "    label_names.append(label_name)\n",
        "\n",
        "  return label_values, label_names"
      ],
      "metadata": {
        "id": "iO0T1wRcFVou"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_nii(input_file, output_directory, label_names):\n",
        "\n",
        "  \"\"\"Function to split a single multilabel nii into individual nii files. Used\n",
        "     for pyradiomics feature extraction. \n",
        "\n",
        "  Inputs: \n",
        "    input_file       : input multi-label nii file \n",
        "    output_directory : where to save the individual nii segments \n",
        "    label_names      : the names of the labels that correspond to the order of \n",
        "                       the values in the nii input_file \n",
        "\n",
        "  Outputs:\n",
        "    saves the individual nii files to the output_directory \n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  if not os.path.isdir(output_directory):\n",
        "    os.mkdir(output_directory)\n",
        "\n",
        "  # save with the values in the files \n",
        "  nii = nib.load(input_file)\n",
        "  header = nii.header \n",
        "  img = nii.get_fdata() \n",
        "  unique_labels = list(np.unique(img))\n",
        "  unique_labels.remove(0) # remove the background \n",
        "\n",
        "  # split and save \n",
        "  num_labels = len(unique_labels)\n",
        "  for n in range(0,num_labels):\n",
        "    ind = np.where(img==unique_labels[n])\n",
        "    vol = np.zeros((img.shape))\n",
        "    vol[ind] = 1\n",
        "    new_img = nib.Nifti1Image(vol, nii.affine, nii.header)\n",
        "    output_filename = os.path.join(output_directory, label_names[n] + '.nii.gz')\n",
        "    nib.save(new_img, output_filename)\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "Rm49POmEFeQe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pyradiomics_3D_features(ct_nifti_path, \n",
        "                                    label_values, \n",
        "                                    label_names, \n",
        "                                    split_pred_nifti_path, \n",
        "                                    nnunet_shape_features_code_mapping_df):\n",
        "\n",
        "  \"\"\"Function to compute pyradiomics 3D features for each label in a nifti file. \n",
        "     \n",
        "\n",
        "  Inputs: \n",
        "    ct_nifti_path            : the CT nifti file \n",
        "    label_values             : the label value for each of the segments from the json file \n",
        "    label_names              : the corresponding label name for each of the segments \n",
        "    split_pred_nifti_path    : where to save the individual nii segments needed \n",
        "                               for pyradiomics\n",
        "    nnunet_shape_features_code_mapping_df : the df where we will obtain the \n",
        "                                            list of the shape features to \n",
        "                                            compute\n",
        "\n",
        "  Outputs:\n",
        "    Writes the features_csv_path_nnunet to disk. \n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  # Get the names of the features from the nnunet_shape_features_code_mapping_df\n",
        "  shape_features = list(nnunet_shape_features_code_mapping_df['shape_feature'].values)\n",
        "\n",
        "  # Instantiate the extractor and modify the settings to keep the 3D shape features\n",
        "  extractor = featureextractor.RadiomicsFeatureExtractor(fn_param)\n",
        "  extractor.settings['minimumROIDimensions'] = 3 \n",
        "  extractor.disableAllFeatures()\n",
        "  extractor.enableFeaturesByName(shape=shape_features) \n",
        "\n",
        "  # Calculate features for each label and create a dataframe\n",
        "  num_labels = len([f for f in os.listdir(split_pred_nifti_path) if f.endswith('.nii.gz')]) # was .nii.gz\n",
        "  print(num_labels)\n",
        "  df_list = [] \n",
        "  for n in range(0,num_labels):\n",
        "    mask_path = os.path.join(split_pred_nifti_path, label_names[n] + '.nii.gz')  # was .nii.gz\n",
        "    #NS\n",
        "    print(mask_path)\n",
        "    print(ct_nifti_path)\n",
        "    print('zzzz')\n",
        "    # Run the extractor \n",
        "    result = extractor.execute(ct_nifti_path, mask_path) # dictionary\n",
        "    # keep only the features we want\n",
        "    # Get the corresponding label number -- all might not be present \n",
        "    corresponding_label_value = label_values[label_names.index(label_names[n])] \n",
        "    dict_keep = {'ReferencedSegment': corresponding_label_value, \n",
        "                 'label_name': label_names[n]}\n",
        "    keys_keep = [f for f in result.keys() if 'original_shape' in f]\n",
        "    # Just keep the feature keys we want\n",
        "    dict_keep_new_values = {key_keep: result[key_keep] for key_keep in keys_keep}\n",
        "    dict_keep.update(dict_keep_new_values)\n",
        "    df1 = pd.DataFrame([dict_keep])\n",
        "    # change values of columns to remove original_shape_\n",
        "    df1.columns = df1.columns.str.replace('original_shape_', '')\n",
        "    # Append to the ReferencedSegment and label_name df \n",
        "    df_list.append(df1)\n",
        "\n",
        "  # concat all label features \n",
        "  df = pd.concat(df_list)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "SBIdR3ZpKhd9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def order_dicom_files_image_position(dcm_directory):\n",
        "  \"\"\"\n",
        "  Orders the dicom files according to image position and orientation. \n",
        "\n",
        "  Arguments:\n",
        "    dcm_directory : input directory of dcm files to put in order \n",
        "\n",
        "  Outputs:\n",
        "    files_sorted   : dcm files in sorted order \n",
        "    sop_all_sorted : the SOPInstanceUIDs in sorted order \n",
        "    pos_all_sorted : the image position in sorted order \n",
        "\n",
        "  \"\"\"\n",
        "  files = [os.path.join(dcm_directory,f) for f in os.listdir(dcm_directory)]\n",
        "\n",
        "  num_files = len(files)\n",
        "\n",
        "  pos_all = []  \n",
        "  sop_all = [] \n",
        "\n",
        "  for n in range(0,num_files):\n",
        "    # read dcm file \n",
        "    filename = files[n]\n",
        "    ds = dcmread(filename)\n",
        "\n",
        "    # get ImageOrientation (0020, 0037)\n",
        "    # ImageOrientation = ds['0x0020','0x0037'].value\n",
        "    ImageOrientation = ds.ImageOrientationPatient\n",
        "\n",
        "    # get ImagePositionPatient (0020, 0032) \n",
        "    # ImagePositionPatient = ds['0x0020','0x0032'].value\n",
        "    ImagePositionPatient = ds.ImagePositionPatient\n",
        "\n",
        "    # calculate z value\n",
        "    x_vector = ImageOrientation[0:3]\n",
        "    y_vector = ImageOrientation[3:]\n",
        "    z_vector = np.cross(x_vector,y_vector)\n",
        "\n",
        "    # multiple z_vector by ImagePositionPatient\n",
        "    pos = np.dot(z_vector,ImagePositionPatient)\n",
        "    pos_all.append(pos)\n",
        "\n",
        "    # get the SOPInstanceUID \n",
        "    # sop = ds['0x0008', '0x0018'].value\n",
        "    sop = ds.SOPInstanceUID\n",
        "    sop_all.append(sop)\n",
        "\n",
        "\n",
        "  #----- order the SOPInstanceUID/files by z value ----# \n",
        "\n",
        "  sorted_ind = np.argsort(pos_all)\n",
        "  pos_all_sorted = np.array(pos_all)[sorted_ind.astype(int)]\n",
        "  sop_all_sorted = np.array(sop_all)[sorted_ind.astype(int)]\n",
        "  files_sorted = np.array(files)[sorted_ind.astype(int)]\n",
        "\n",
        "  return files_sorted, sop_all_sorted, pos_all_sorted"
      ],
      "metadata": {
        "id": "HYjMey5mKq6O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_structured_report_metajson_for_shape_features(SeriesInstanceUID, \n",
        "                                                         SOPInstanceUID_seg,\n",
        "                                                         seg_file, \n",
        "                                                         dcm_directory, \n",
        "                                                         segments_code_mapping_df,\n",
        "                                                         shape_features_code_mapping_df,\n",
        "                                                         df_features, \n",
        "                                                         SegmentAlgorithmName\n",
        "                                                         ):\n",
        "  \n",
        "  \"\"\"Function that creates the metajson necessary for the creation of a\n",
        "  structured report from a pandas dataframe of label names and features for \n",
        "  each. \n",
        "\n",
        "  Inputs: \n",
        "    SeriesInstanceUID               : SeriesInstanceUID of the corresponding CT \n",
        "                                      file \n",
        "    SOPInstanceUID_seg              : SOPInstanceUID of the corresponding SEG file \n",
        "    seg_file                        : filename of SEG DCM file \n",
        "    dcm_directory                   : ct directory that will be sorted in \n",
        "                                      terms of axial ordering according to the \n",
        "                                      ImagePositionPatient and ImageOrientation \n",
        "                                      fields\n",
        "    segments_code_mapping_df        : dataframe that holds the names of the \n",
        "                                      segments and the associated code values etc.\n",
        "    shape_features_code_mapping_df  : dataframe that holds the names of the \n",
        "                                      features and the associated code values etc. \n",
        "    df_features                     : a pandas dataframe holding the segments and a \n",
        "                                      set of 3D shape features for each \n",
        "    SegmentAlgorithmName            : the name of the algorithm used to create the \n",
        "                                      segmentations - e.g. '3d_fullres_tta_nnUnet'\n",
        "\n",
        "  Outputs:\n",
        "    Returns the metajson for the structured report that will then be used by\n",
        "    dcmqi tid1500writer to create a structured report \n",
        "  \"\"\" \n",
        "\n",
        "  # --- Get the version number for the pyradiomics package --- #\n",
        "\n",
        "  pyradiomics_version_number = str(radiomics.__version__)\n",
        "  \n",
        "  # --- Sort the dcm files first according to --- # \n",
        "  # --- ImagePositionPatient and ImageOrientation --- #\n",
        "\n",
        "  files_sorted, sop_all_sorted, pos_all_sorted = order_dicom_files_image_position(dcm_directory)\n",
        "  files_sorted = [os.path.basename(f) for f in files_sorted]\n",
        "\n",
        "  # --- Create the header for the json --- # \n",
        "  \n",
        "  inputMetadata = {}\n",
        "  inputMetadata[\"@schema\"]= \"https://raw.githubusercontent.com/qiicr/dcmqi/master/doc/schemas/sr-tid1500-schema.json#\"\n",
        "  # inputMetadata[\"SeriesDescription\"] = \"Measurements\"\n",
        "  inputMetadata[\"SeriesDescription\"] = SegmentAlgorithmName + '_' + \"Measurements\"\n",
        "  inputMetadata[\"SeriesNumber\"] = \"1001\"\n",
        "  inputMetadata[\"InstanceNumber\"] = \"1\"\n",
        "\n",
        "  inputMetadata[\"compositeContext\"] = [seg_file] # not full path\n",
        "\n",
        "  inputMetadata[\"imageLibrary\"] = files_sorted # not full path \n",
        "\n",
        "   # inputMetadata[\"observerContext\"] = {\n",
        "  #                                     \"ObserverType\": \"PERSON\",\n",
        "  #                                     \"PersonObserverName\": \"Reader1\"\n",
        "  #                                   }\n",
        "  # inputMetadata[\"observerContext\"] = {\n",
        "  #                     \"ObserverType\": \"DEVICE\",\n",
        "  #                     \"DeviceObserverName\": \"pyradiomics\",\n",
        "  #                     \"DeviceObserverModelName\": \"v3.0.1\"\n",
        "  #                   }\n",
        "  inputMetadata[\"observerContext\"] = {\n",
        "                      \"ObserverType\": \"DEVICE\",\n",
        "                      \"DeviceObserverName\": \"pyradiomics\",\n",
        "                      \"DeviceObserverModelName\": pyradiomics_version_number\n",
        "                    }\n",
        "\n",
        "  inputMetadata[\"VerificationFlag\"]  = \"UNVERIFIED\"\n",
        "  inputMetadata[\"CompletionFlag\"] =  \"COMPLETE\"\n",
        "  inputMetadata[\"activitySession\"] = \"1\"\n",
        "  inputMetadata[\"timePoint\"] = \"1\"\n",
        "\n",
        "  # ------------------------------------------------------------------------- # \n",
        "  # --- Create the measurement_dict for each segment - holds all features --- # \n",
        "\n",
        "  measurement = [] \n",
        "\n",
        "  # --- Now create the dict for all features and all segments --- #\n",
        "\n",
        "  # --- Loop over the number of segments --- #\n",
        "\n",
        "  # number of rows in the df_features \n",
        "  num_segments = df_features.shape[0]\n",
        "\n",
        "  # Array of dictionaries - one dictionary for each segment \n",
        "  measurement_across_segments_combined = [] \n",
        "\n",
        "  for segment_id in range(0,num_segments):\n",
        "\n",
        "    ReferencedSegment = df_features['ReferencedSegment'].values[segment_id]\n",
        "    FindingSite = df_features['label_name'].values[segment_id]\n",
        "\n",
        "    print('segment_id: ' + str(segment_id))\n",
        "    print('ReferencedSegment: ' + str(ReferencedSegment))\n",
        "    print('FindingSite: ' + str(FindingSite))\n",
        "\n",
        "    # --- Create the dict for the Measurements group --- # \n",
        "    TrackingIdentifier = \"Measurements group \" + str(ReferencedSegment)\n",
        "\n",
        "    segment_row = segments_code_mapping_df[segments_code_mapping_df[\"segment\"] == FindingSite]\n",
        "    # print(segment_row)\n",
        "        \n",
        "    my_dict = {\n",
        "      \"TrackingIdentifier\": str(TrackingIdentifier),\n",
        "      \"ReferencedSegment\": int(ReferencedSegment),\n",
        "      \"SourceSeriesForImageSegmentation\": str(SeriesInstanceUID),\n",
        "      \"segmentationSOPInstanceUID\": str(SOPInstanceUID_seg),\n",
        "      \"Finding\": {\n",
        "        \"CodeValue\": \"113343008\",\n",
        "        \"CodingSchemeDesignator\": \"SCT\",\n",
        "        \"CodeMeaning\": \"Organ\"\n",
        "      }, \n",
        "      \"FindingSite\": {\n",
        "        \"CodeValue\": str(segment_row[\"FindingSite_CodeValue\"].values[0]),\n",
        "        \"CodingSchemeDesignator\": str(segment_row[\"FindingSite_CodingSchemeDesignator\"].values[0]),\n",
        "        \"CodeMeaning\": str(segment_row[\"FindingSite_CodeMeaning\"].values[0])\n",
        "      }\n",
        "    }\n",
        "\n",
        "    measurement = []  \n",
        "    # number of features - number of columns in df_features - 2 (label_name and ReferencedSegment)\n",
        "    num_values = len(df_features.columns)-2 \n",
        "\n",
        "    feature_list = df_features.columns[2:] # remove first two \n",
        "\n",
        "\n",
        "    # For each measurement per region segment\n",
        "    for n in range(0,num_values): \n",
        "      measurement_dict = {}\n",
        "      row = df_features.loc[df_features['label_name'] == FindingSite]\n",
        "      feature_row = shape_features_code_mapping_df.loc[shape_features_code_mapping_df[\"shape_feature\"] == feature_list[n]]\n",
        "      value = str(np.round(row[feature_list[n]].values[0],3))\n",
        "      measurement_dict[\"value\"] = value\n",
        "      measurement_dict[\"quantity\"] = {}\n",
        "      measurement_dict[\"quantity\"][\"CodeValue\"] = str(feature_row[\"quantity_CodeValue\"].values[0])\n",
        "      measurement_dict[\"quantity\"][\"CodingSchemeDesignator\"] = str(feature_row[\"quantity_CodingSchemeDesignator\"].values[0])\n",
        "      measurement_dict[\"quantity\"][\"CodeMeaning\"] = str(feature_row[\"quantity_CodeMeaning\"].values[0])\n",
        "      measurement_dict[\"units\"] = {}\n",
        "      measurement_dict[\"units\"][\"CodeValue\"] = str(feature_row[\"units_CodeValue\"].values[0])\n",
        "      measurement_dict[\"units\"][\"CodingSchemeDesignator\"] = str(feature_row[\"units_CodingSchemeDesignator\"].values[0])\n",
        "      measurement_dict[\"units\"][\"CodeMeaning\"] = str(feature_row[\"units_CodeMeaning\"].values[0])\n",
        "      measurement_dict[\"measurementAlgorithmIdentification\"] = {}\n",
        "      measurement_dict[\"measurementAlgorithmIdentification\"][\"AlgorithmName\"] = \"pyradiomics\"\n",
        "      measurement_dict[\"measurementAlgorithmIdentification\"][\"AlgorithmVersion\"] = str(pyradiomics_version_number)\n",
        "      measurement.append(measurement_dict) \n",
        "\n",
        "    measurement_combined_dict = {}\n",
        "    measurement_combined_dict['measurementItems'] = measurement # measurement is an array of dictionaries \n",
        "\n",
        "    output_dict_one_segment = {**my_dict, **measurement_combined_dict}\n",
        "\n",
        "    # append to array for all segments \n",
        "\n",
        "    measurement_across_segments_combined.append(output_dict_one_segment)\n",
        "\n",
        "  # --- Add the measurement data --- # \n",
        "\n",
        "  inputMetadata[\"Measurements\"] = {}\n",
        "  inputMetadata[\"Measurements\"] = measurement_across_segments_combined\n",
        "\n",
        "  return inputMetadata\n"
      ],
      "metadata": {
        "id": "CDU5sEH3F9QK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7kCysKk3GwX",
        "outputId": "7b7b31a5-662f-404d-f9b1-343c2e82af1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "gsutil cp gs://midrc-analysis-bwh/bpr-results/seg_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nrrd /content/nrrd_data\n",
            "gsutil cp gs://midrc-analysis-bwh/bpr-results/ct_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nrrd /content/nrrd_data\n",
            "gsutil cp gs://midrc-analysis-bwh/bpr-results/dcmseg_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952 /content/dcm_data\n",
            "converting NRRD to NII\n",
            "\n",
            "Running 'plastimatch convert' with the specified arguments:\n",
            "  --input /content/nrrd_data/ct_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nrrd\n",
            "  --output-img /content/nifti_data/ct_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nii\n",
            "... Done.\n",
            "\n",
            "Running 'plastimatch convert' with the specified arguments:\n",
            "  --input /content/nrrd_data/seg_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nrrd\n",
            "  --interpolation nn\n",
            "  --output-img /content/nifti_data/seg_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nii\n",
            "... Done.\n"
          ]
        }
      ],
      "source": [
        "# Processing series\n",
        "\n",
        "path_downloaded = '/content/downloaded_data'\n",
        "path_nifti = '/content/nifti_data'\n",
        "path_json =  '/content/json_data'\n",
        "path_nrrd = '/content/nrrd_data'\n",
        "path_dcm = '/content/dcm_data'\n",
        "path_labels = '/content/labels'\n",
        "path_sr = '/content/sr'\n",
        "\n",
        "good_seriesuids = ['1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952']\n",
        "\n",
        "#good_seriesuids = [seriesuid_list[0]]\n",
        "\n",
        "k=0\n",
        "for seriesuid in good_seriesuids:\n",
        "  k+=1\n",
        "  print(k)\n",
        "\n",
        "  # clean up from previous iterations and recreate temp directories\n",
        "  if 1:\n",
        "    for x in [path_downloaded, path_nifti, path_json, path_nrrd, path_dcm, path_labels, path_sr]:\n",
        "      if os.path.isdir(x):\n",
        "        try:\n",
        "          shutil.rmtree(x)\n",
        "        except OSError as err:\n",
        "          print(\"Error: %s : %s\" % (x, err.strerror))  \n",
        "      os.mkdir(x)\n",
        "\n",
        "  file_gs_uri_seg = \"gs://%s/%sseg_%s.nrrd\" % (bucket_name, bucket_path, seriesuid) # \"/\"  exists in the path\n",
        "  file_gs_uri_ct = \"gs://%s/%sct_%s.nrrd\" % (bucket_name, bucket_path, seriesuid)\n",
        "  file_gs_uri_dcmseg = \"gs://%s/%sdcmseg_%s\" % (bucket_name, bucket_path, seriesuid)\n",
        "  \n",
        "  cmd1 = \"gsutil cp %s %s\" % (file_gs_uri_seg, path_nrrd)\n",
        "  print(cmd1)\n",
        "  os.system(cmd1)\n",
        "  \n",
        "  cmd2 = \"gsutil cp %s %s\" % (file_gs_uri_ct, path_nrrd)\n",
        "  print(cmd2)\n",
        "  os.system(cmd2)\n",
        "  \n",
        "  cmd3 = \"gsutil cp %s %s\" % (file_gs_uri_dcmseg, path_dcm)\n",
        "  print(cmd3)\n",
        "  os.system(cmd3)\n",
        "\n",
        "  fn_seg_nrrd = os.path.join(path_nrrd, 'seg_%s.nrrd' % seriesuid)\n",
        "  fn_ct_nrrd = os.path.join(path_nrrd, 'ct_%s.nrrd' % seriesuid)\n",
        "  fn_param = os.path.join('/content','param_ct.yaml')\n",
        "\n",
        "  print('converting NRRD to NII')\n",
        "  fn_ct_nifti = os.path.join(path_nifti,  \"ct_%s.nii\" % seriesuid)\n",
        "  log_file_path_ct_nifti = os.path.join(path_nifti, 'pypla_ct.log')\n",
        "  convert_args_ct = {\"input\" : fn_ct_nrrd, \"output-img\" : fn_ct_nifti}\n",
        "  verbose = True\n",
        "  pypla.convert(verbose = verbose, path_to_log_file = log_file_path_ct_nifti, **convert_args_ct)\n",
        "  \n",
        "  fn_seg_nifti = os.path.join(path_nifti,  \"seg_%s.nii\" % seriesuid)\n",
        "  log_file_path_seg_nifti = os.path.join(path_nifti, 'pypla_seg.log')\n",
        "  convert_args_seg = {\"input\" : fn_seg_nrrd, \"interpolation\" : \"nn\", \"output-img\" : fn_seg_nifti}\n",
        "  verbose = True\n",
        "  pypla.convert(verbose = verbose, path_to_log_file = log_file_path_seg_nifti, **convert_args_seg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn_seg_dcm = os.path.join(path_dcm, 'dcmseg_%s' % seriesuid)\n",
        "fn_seg_code_mapping = os.path.join('/content','segments_code_mapping.csv')\n",
        "fn_feature_code_mapping = os.path.join('/content','shape_features_code_mapping.csv')\n",
        "fn_seg_meta = os.path.join('/content','lung_seg_meta.json')\n",
        "\n",
        "seg_code_mapping_df = pd.read_csv(fn_seg_code_mapping)\n",
        "feature_code_mapping_df = pd.read_csv(fn_feature_code_mapping)\n"
      ],
      "metadata": {
        "id": "zfWpUuKmRHGV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_values, label_names = get_label_and_names_from_metadata_json(fn_seg_meta)\n",
        "print(label_values, label_names)\n",
        "split_nii( fn_seg_nifti , path_labels, label_names)"
      ],
      "metadata": {
        "id": "AFC2mG2aiATA",
        "outputId": "7db3ecc0-bf54-4446-a291-48bff78c16f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ContentCreatorName': 'MIDRC', 'ClinicalTrialSeriesID': '0', 'ClinicalTrialTimePointID': '0', 'SeriesDescription': 'Segmentation', 'SeriesNumber': '300', 'InstanceNumber': '1', 'BodyPartExamined': 'Chest', 'segmentAttributes': [[{'labelID': 1, 'SegmentDescription': 'Right lung', 'SegmentAlgorithmType': 'AUTOMATIC', 'SegmentAlgorithmName': 'lungmask R231', 'SegmentedPropertyCategoryCodeSequence': {'CodeValue': '123037004', 'CodingSchemeDesignator': 'SCT', 'CodeMeaning': 'Anatomical Structure'}, 'SegmentedPropertyTypeCodeSequence': {'CodeValue': '39607008', 'CodingSchemeDesignator': 'SCT', 'CodeMeaning': 'Lung'}, 'SegmentedPropertyTypeModifierCodeSequence': {'CodeValue': '24028007', 'CodingSchemeDesignator': 'SCT', 'CodeMeaning': 'Right'}, 'recommendedDisplayRGBValue': [11, 156, 191]}, {'labelID': 2, 'SegmentDescription': 'Left lung', 'SegmentAlgorithmType': 'AUTOMATIC', 'SegmentAlgorithmName': 'lungmask R231', 'SegmentedPropertyCategoryCodeSequence': {'CodeValue': '123037004', 'CodingSchemeDesignator': 'SCT', 'CodeMeaning': 'Anatomical Structure'}, 'SegmentedPropertyTypeCodeSequence': {'CodeValue': '39607008', 'CodingSchemeDesignator': 'SCT', 'CodeMeaning': 'Lung'}, 'SegmentedPropertyTypeModifierCodeSequence': {'CodeValue': '7771000', 'CodingSchemeDesignator': 'SCT', 'CodeMeaning': 'Left'}, 'recommendedDisplayRGBValue': [91, 154, 223]}]], 'ContentLabel': 'SEGMENTATION', 'ContentDescription': 'Image segmentation', 'ClinicalTrialCoordinatingCenterName': 'dcmqi'}\n",
            "num_regions: 2\n",
            "[1, 2] ['Right lung', 'Left lung']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $path_labels"
      ],
      "metadata": {
        "id": "w9oxkEpOsZBk",
        "outputId": "d584bed8-2b71-43ea-c6bc-b9775554a79e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Left lung.nii.gz'  'Right lung.nii.gz'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = dcmread(fn_seg_dcm)\n",
        "sop = ds.SOPInstanceUID\n",
        "print(sop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wke0StbFZhPf",
        "outputId": "9b29557f-71e5-483f-9dcc-91a8f5a4e8c4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.276.0.7230010.3.1.4.481034752.4023.1667497562.213485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = compute_pyradiomics_3D_features(fn_ct_nifti, \n",
        "                                    label_values, \n",
        "                                    label_names, \n",
        "                                    path_labels, \n",
        "                                    feature_code_mapping_df)"
      ],
      "metadata": {
        "id": "V26sJMBRg7XG",
        "outputId": "2196ac12-56a7-4ad9-b8a5-df1f00615310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:radiomics.featureextractor:Loading parameter file /content/param_ct.yaml\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "/content/labels/Right lung.nii.gz\n",
            "/content/nifti_data/ct_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nii\n",
            "zzzz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:radiomics.imageoperations:Applying resampling from spacing [0.703125 0.703125 2.5     ] and size [512 512 145] to spacing [1. 1. 1.] and size [211, 232, 309]\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "Feature Compactness1 is deprecated, use with caution!\n",
            "WARNING:radiomics.shape:Feature Compactness1 is deprecated, use with caution!\n",
            "Feature Compactness2 is deprecated, use with caution!\n",
            "WARNING:radiomics.shape:Feature Compactness2 is deprecated, use with caution!\n",
            "Feature SphericalDisproportion is deprecated, use with caution!\n",
            "WARNING:radiomics.shape:Feature SphericalDisproportion is deprecated, use with caution!\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Adding image type \"LoG\" with custom settings: {'sigma': [1.0, 2.0, 3.0, 4.0, 5.0]}\n",
            "INFO:radiomics.featureextractor:Adding image type \"Wavelet\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 1\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-1-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 2\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-2-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 3\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-3-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 4\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-4-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 5\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-5-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet LLH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LLH image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet LHL\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LHL image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet LHH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LHH image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HLL\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HLL image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HLH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HLH image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HHL\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HHL image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HHH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HHH image\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LLL image\n",
            "INFO:radiomics.featureextractor:Calculating features with label: 1\n",
            "INFO:radiomics.featureextractor:Loading image and mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/labels/Left lung.nii.gz\n",
            "/content/nifti_data/ct_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952.nii\n",
            "zzzz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:radiomics.imageoperations:Applying resampling from spacing [0.703125 0.703125 2.5     ] and size [512 512 145] to spacing [1. 1. 1.] and size [156, 215, 232]\n",
            "INFO:radiomics.featureextractor:Computing shape\n",
            "Feature Compactness1 is deprecated, use with caution!\n",
            "WARNING:radiomics.shape:Feature Compactness1 is deprecated, use with caution!\n",
            "Feature Compactness2 is deprecated, use with caution!\n",
            "WARNING:radiomics.shape:Feature Compactness2 is deprecated, use with caution!\n",
            "Feature SphericalDisproportion is deprecated, use with caution!\n",
            "WARNING:radiomics.shape:Feature SphericalDisproportion is deprecated, use with caution!\n",
            "INFO:radiomics.featureextractor:Adding image type \"Original\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Adding image type \"LoG\" with custom settings: {'sigma': [1.0, 2.0, 3.0, 4.0, 5.0]}\n",
            "INFO:radiomics.featureextractor:Adding image type \"Wavelet\" with custom settings: {}\n",
            "INFO:radiomics.featureextractor:Calculating features for original image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 1\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-1-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 2\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-2-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 3\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-3-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 4\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-4-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing LoG with sigma 5\n",
            "INFO:radiomics.featureextractor:Calculating features for log-sigma-5-0-mm-3D image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet LLH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LLH image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet LHL\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LHL image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet LHH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LHH image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HLL\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HLL image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HLH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HLH image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HHL\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HHL image\n",
            "INFO:radiomics.imageoperations:Computing Wavelet HHH\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-HHH image\n",
            "INFO:radiomics.featureextractor:Calculating features for wavelet-LLL image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metajson = create_structured_report_metajson_for_shape_features(seriesuid, \n",
        "                                                         sop,\n",
        "                                                         fn_seg_dcm, \n",
        "                                                         path_downloaded, \n",
        "                                                         seg_code_mapping_df,\n",
        "                                                         feature_code_mapping_df,\n",
        "                                                         df_out, \n",
        "                                                         'lungmask'\n",
        "                                                         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxhI-IX7GbOi",
        "outputId": "2ac9e349-d5b4-48f9-9695-26cad1c39d7e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segment_id: 0\n",
            "ReferencedSegment: 1\n",
            "FindingSite: Right lung\n",
            "segment_id: 1\n",
            "ReferencedSegment: 2\n",
            "FindingSite: Left lung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metajson"
      ],
      "metadata": {
        "id": "iwZPHgGbX31Q",
        "outputId": "2ef3ffd9-015f-43ce-c20b-5370464f7793",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'@schema': 'https://raw.githubusercontent.com/qiicr/dcmqi/master/doc/schemas/sr-tid1500-schema.json#',\n",
              " 'SeriesDescription': 'lungmask_Measurements',\n",
              " 'SeriesNumber': '1001',\n",
              " 'InstanceNumber': '1',\n",
              " 'compositeContext': ['/content/dcm_data/dcmseg_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952'],\n",
              " 'imageLibrary': [],\n",
              " 'observerContext': {'ObserverType': 'DEVICE',\n",
              "  'DeviceObserverName': 'pyradiomics',\n",
              "  'DeviceObserverModelName': 'v3.0.1'},\n",
              " 'VerificationFlag': 'UNVERIFIED',\n",
              " 'CompletionFlag': 'COMPLETE',\n",
              " 'activitySession': '1',\n",
              " 'timePoint': '1',\n",
              " 'Measurements': [{'TrackingIdentifier': 'Measurements group 1',\n",
              "   'ReferencedSegment': 1,\n",
              "   'SourceSeriesForImageSegmentation': '1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952',\n",
              "   'segmentationSOPInstanceUID': '1.2.276.0.7230010.3.1.4.481034752.4023.1667497562.213485',\n",
              "   'Finding': {'CodeValue': '113343008',\n",
              "    'CodingSchemeDesignator': 'SCT',\n",
              "    'CodeMeaning': 'Organ'},\n",
              "   'FindingSite': {'CodeValue': '39607008',\n",
              "    'CodingSchemeDesignator': 'SCT',\n",
              "    'CodeMeaning': 'Lung'},\n",
              "   'measurementItems': [{'value': '0.78',\n",
              "     'quantity': {'CodeValue': 'Q3CK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Elongation'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.487',\n",
              "     'quantity': {'CodeValue': 'N17B',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Flatness'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '124.805',\n",
              "     'quantity': {'CodeValue': '7J51',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Least Axis in 3D Length'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '256.166',\n",
              "     'quantity': {'CodeValue': 'TDIC',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Major Axis in 3D Length'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '311.657',\n",
              "     'quantity': {'CodeValue': 'L0JK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Maximum 3D Diameter of a Mesh'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '3826057.542',\n",
              "     'quantity': {'CodeValue': 'RNU0',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Volume of Mesh'},\n",
              "     'units': {'CodeValue': 'mm3',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'cubic millimeter '},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '199.769',\n",
              "     'quantity': {'CodeValue': 'P9VJ',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Minor Axis in 3D Length'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.58',\n",
              "     'quantity': {'CodeValue': 'QCFX',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Sphericity'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '203823.06',\n",
              "     'quantity': {'CodeValue': 'C0JK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Surface Area of Mesh'},\n",
              "     'units': {'CodeValue': 'mm2',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'square millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.053',\n",
              "     'quantity': {'CodeValue': '2PR5',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Surface to Volume Ratio'},\n",
              "     'units': {'CodeValue': '/mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'per millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '3826321.0',\n",
              "     'quantity': {'CodeValue': 'YEKZ',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Volume from Voxel Summation'},\n",
              "     'units': {'CodeValue': 'mm3',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'cubic millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.023',\n",
              "     'quantity': {'CodeValue': 'SKGS',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Compactness 1'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.196',\n",
              "     'quantity': {'CodeValue': 'BQWJ',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Compactness 2'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '1.723',\n",
              "     'quantity': {'CodeValue': 'KRCK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Spherical Disproportion'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}}]},\n",
              "  {'TrackingIdentifier': 'Measurements group 2',\n",
              "   'ReferencedSegment': 2,\n",
              "   'SourceSeriesForImageSegmentation': '1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952',\n",
              "   'segmentationSOPInstanceUID': '1.2.276.0.7230010.3.1.4.481034752.4023.1667497562.213485',\n",
              "   'Finding': {'CodeValue': '113343008',\n",
              "    'CodingSchemeDesignator': 'SCT',\n",
              "    'CodeMeaning': 'Organ'},\n",
              "   'FindingSite': {'CodeValue': '39607008',\n",
              "    'CodingSchemeDesignator': 'SCT',\n",
              "    'CodeMeaning': 'Lung'},\n",
              "   'measurementItems': [{'value': '0.871',\n",
              "     'quantity': {'CodeValue': 'Q3CK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Elongation'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.461',\n",
              "     'quantity': {'CodeValue': 'N17B',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Flatness'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '88.497',\n",
              "     'quantity': {'CodeValue': '7J51',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Least Axis in 3D Length'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '192.164',\n",
              "     'quantity': {'CodeValue': 'TDIC',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Major Axis in 3D Length'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '225.364',\n",
              "     'quantity': {'CodeValue': 'L0JK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Maximum 3D Diameter of a Mesh'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '1514095.083',\n",
              "     'quantity': {'CodeValue': 'RNU0',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Volume of Mesh'},\n",
              "     'units': {'CodeValue': 'mm3',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'cubic millimeter '},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '167.422',\n",
              "     'quantity': {'CodeValue': 'P9VJ',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Minor Axis in 3D Length'},\n",
              "     'units': {'CodeValue': 'mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.502',\n",
              "     'quantity': {'CodeValue': 'QCFX',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Sphericity'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '127067.783',\n",
              "     'quantity': {'CodeValue': 'C0JK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Surface Area of Mesh'},\n",
              "     'units': {'CodeValue': 'mm2',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'square millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.084',\n",
              "     'quantity': {'CodeValue': '2PR5',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Surface to Volume Ratio'},\n",
              "     'units': {'CodeValue': '/mm',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'per millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '1514440.0',\n",
              "     'quantity': {'CodeValue': 'YEKZ',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Volume from Voxel Summation'},\n",
              "     'units': {'CodeValue': 'mm3',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'cubic millimeter'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.019',\n",
              "     'quantity': {'CodeValue': 'SKGS',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Compactness 1'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '0.126',\n",
              "     'quantity': {'CodeValue': 'BQWJ',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Compactness 2'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}},\n",
              "    {'value': '1.993',\n",
              "     'quantity': {'CodeValue': 'KRCK',\n",
              "      'CodingSchemeDesignator': 'IBSI',\n",
              "      'CodeMeaning': 'Spherical Disproportion'},\n",
              "     'units': {'CodeValue': '1',\n",
              "      'CodingSchemeDesignator': 'UCUM',\n",
              "      'CodeMeaning': 'no units'},\n",
              "     'measurementAlgorithmIdentification': {'AlgorithmName': 'pyradiomics',\n",
              "      'AlgorithmVersion': 'v3.0.1'}}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_structured_report( inputMetadata, sr_json_path, dcm_directory, sr_path, pred_dicomseg_path):\n",
        "  with open(sr_json_path, 'w') as f:\n",
        "    json.dump(inputMetadata, f, indent=2)\n",
        "  print ('wrote out json for shape features')\n",
        "\n",
        "  # --- Save the SR for nnUNet shape features --- # \n",
        "  # inputImageLibraryDirectory = os.path.join(\"/content\", \"raw\")\n",
        "  # outputDICOM = os.path.join(\"/content\",\"features_sr.dcm\")\n",
        "  # inputCompositeContextDirectory = os.path.join(\"/content\",\"seg\")\n",
        "  inputImageLibraryDirectory = dcm_directory\n",
        "  # outputDICOM = sr_json_path\n",
        "  outputDICOM = sr_path\n",
        "  # the name of the folder where the seg files are located \n",
        "  inputCompositeContextDirectory = pred_dicomseg_path  # os.path.basename(pred_dicomseg_path) # might need to check this\n",
        "  inputMetadata_json = sr_json_path \n",
        "\n",
        "  print ('inputImageLibraryDirectory: ' + str(inputImageLibraryDirectory))\n",
        "  print ('outputDICOM: ' + str(outputDICOM))\n",
        "  print ('inputCompositeContextDirectory: ' + str(inputCompositeContextDirectory))\n",
        "  print ('inputMetadata_json: ' + str(inputMetadata_json)) \n",
        "  !tid1500writer --inputImageLibraryDirectory $inputImageLibraryDirectory \\\n",
        "                --outputDICOM $outputDICOM  \\\n",
        "                --inputCompositeContextDirectory $inputCompositeContextDirectory \\\n",
        "                --inputMetadata $inputMetadata_json\n",
        "  print ('wrote out SR for shape features')\n"
      ],
      "metadata": {
        "id": "wIhPGH0HYkUB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn_sr = '/content/sr/structured_report_radiomics.dcm'\n",
        "fn_metadata_json = '/content/structured_report_metadata.json'\n",
        "save_structured_report( metajson, fn_metadata_json, path_downloaded, fn_sr, path_dcm )"
      ],
      "metadata": {
        "id": "sYzzllqWY0G4",
        "outputId": "f3af1a92-3fa3-4e1a-e932-7717038ef4a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wrote out json for shape features\n",
            "inputImageLibraryDirectory: /content/downloaded_data\n",
            "outputDICOM: /content/sr/structured_report_radiomics.dcm\n",
            "inputCompositeContextDirectory: /content/dcm_data\n",
            "inputMetadata_json: /content/structured_report_metadata.json\n",
            "dcmqi repository URL: git@github.com:QIICR/dcmqi.git revision: 1153738 tag: v1.2.5\n",
            "Total measurement groups: 2\n",
            "Adding to compositeContext: /content/dcm_data/dcmseg_1.2.826.0.1.3680043.10.474.419639.149051607502633615235577977952\n",
            "Composite Context has been initialized\n",
            "SR saved!\n",
            "wrote out SR for shape features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_structured_report_for_shape_features(SeriesInstanceUID, \n",
        "                                              SOPInstanceUID_seg, \n",
        "                                              pred_dicomseg_path, \n",
        "                                              dicomseg_json_path, \n",
        "                                              dcm_directory, \n",
        "                                              pred_nifti_path, \n",
        "                                              nnunet_base_path, \n",
        "                                              ct_nifti_path, \n",
        "                                              segments_code_mapping_df,\n",
        "                                              shape_features_code_mapping_df,\n",
        "                                              sr_json_path,\n",
        "                                              sr_path, \n",
        "                                              SegmentAlgorithmName\n",
        "                                              ):\n",
        "  \n",
        "  \"\"\" This function creates the SR necessary for the nnUNet shape features \n",
        "\n",
        "  Inputs: \n",
        "  SeriesInstanceUID               : SeriesInstanceUID of the corresponding CT \n",
        "                                    file \n",
        "  SOPInstanceUID_seg              : SOPInstanceUID of the corresponding SEG file \n",
        "  pred_dicomseg_path              : filename of DICOM SEG file \n",
        "  dicomseg_json_path              : json file for DICOM SEG file \n",
        "  dcm_directory                   : list of ct files that will be sorted in \n",
        "                                    terms of axial ordering according to the \n",
        "                                    ImagePositionPatient and ImageOrientation \n",
        "                                    fields\n",
        "  pred_nifti_path                 : predictions in nifti format \n",
        "  nnunet_base_path                : path to hold the split nifti files \n",
        "  ct_nifti_path                   : filename for CT nifti file\n",
        "  segments_code_mapping_df        : dataframe that holds the names of the \n",
        "                                    segments and the associated code values etc.\n",
        "  shape_features_code_mapping_df  : dataframe that holds the names of the \n",
        "                                    features and the associated code values etc. \n",
        "  sr_json_path                    : the path that the metajson for the SR for \n",
        "                                    the 3D shape features will be saved \n",
        "  sr_path                         : the path that the SR for the 3D shape \n",
        "                                    features will be saved \n",
        "  SegmentAlgorithmName            : the name of the algorithm used to create the \n",
        "                                    segmentations - e.g. '3d_fullres_tta_nnUnet'\n",
        "\n",
        "  Outputs:\n",
        "    Returns the metajson for the structured report that will then be used by\n",
        "    dcmqi tid1500writer to create a structured report \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # --- get label values and names from metajson file --- #\n",
        "  label_values, label_names = get_label_and_names_from_metadata_json(dicomseg_json_path)\n",
        "\n",
        "  # --- split the multilabel nifti into individual files --- #\n",
        "  split_pred_nii_path = os.path.join(nnunet_base_path, \"split_nii\")\n",
        "  if not os.path.isdir(split_pred_nii_path): \n",
        "    os.mkdir(split_pred_nii_path)\n",
        "  split_nii(pred_nifti_path, split_pred_nii_path, label_names)\n",
        "\n",
        "  # --- compute features and save csv for each region --- #\n",
        "  if not os.path.isdir(features_csv_path_nnunet):\n",
        "    os.mkdir(features_csv_path_nnunet) \n",
        "  df_features = compute_pyradiomics_3D_features(ct_nifti_path, \n",
        "                                                label_values, \n",
        "                                                label_names,\n",
        "                                                split_pred_nii_path, \n",
        "                                                nnunet_shape_features_code_mapping_df)\n",
        "  print ('created df_features')\n",
        "  \n",
        "  # --- upload csv file to bucket --- #\n",
        "  # !$s5cmd_path --endpoint-url https://storage.googleapis.com cp $pred_features_csv_path $gs_uri_features_csv_file\n",
        "\n",
        "  # remove nii files after saving out pyradiomics results\n",
        "  !rm $split_pred_nii_path/*\n",
        "  # remove csv \n",
        "  # !rm $pred_features_csv_path\n",
        "\n",
        "  # --- Create the final metadata for the SR --- #\n",
        "  inputMetadata = create_structured_report_metajson_for_shape_features(SeriesInstanceUID, \n",
        "                                                                       SOPInstanceUID_seg,\n",
        "                                                                       pred_dicomseg_path, \n",
        "                                                                       dcm_directory, \n",
        "                                                                       nnunet_segments_code_mapping_df, \n",
        "                                                                       nnunet_shape_features_code_mapping_df,\n",
        "                                                                       df_features, \n",
        "                                                                       SegmentAlgorithmName)\n",
        "\n",
        "  print ('created SR json for shape features')\n",
        "\n",
        "  # --- Write out json --- #\n",
        "\n",
        "  with open(sr_json_path, 'w') as f:\n",
        "    json.dump(inputMetadata, f, indent=2)\n",
        "  print ('wrote out json for shape features')\n",
        "\n",
        "  # --- Save the SR for nnUNet shape features --- # \n",
        "  # inputImageLibraryDirectory = os.path.join(\"/content\", \"raw\")\n",
        "  # outputDICOM = os.path.join(\"/content\",\"features_sr.dcm\")\n",
        "  # inputCompositeContextDirectory = os.path.join(\"/content\",\"seg\")\n",
        "  inputImageLibraryDirectory = dcm_directory\n",
        "  # outputDICOM = sr_json_path\n",
        "  outputDICOM = sr_path\n",
        "  # the name of the folder where the seg files are located \n",
        "  inputCompositeContextDirectory = os.path.basename(pred_dicomseg_path) # might need to check this\n",
        "  inputMetadata_json = sr_json_path \n",
        "\n",
        "  print ('inputImageLibraryDirectory: ' + str(inputImageLibraryDirectory))\n",
        "  print ('outputDICOM: ' + str(outputDICOM))\n",
        "  print ('inputCompositeContextDirectory: ' + str(inputCompositeContextDirectory))\n",
        "  print ('inputMetadata_json: ' + str(inputMetadata_json)) \n",
        "  !tid1500writer --inputImageLibraryDirectory $inputImageLibraryDirectory \\\n",
        "                --outputDICOM $outputDICOM  \\\n",
        "                --inputCompositeContextDirectory $inputCompositeContextDirectory \\\n",
        "                --inputMetadata $inputMetadata_json\n",
        "  print ('wrote out SR for shape features')\n",
        "\n",
        "  return\n"
      ],
      "metadata": {
        "id": "ht9QRarlbQf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}